{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML('<style>.p-Widget.jp-OutputPrompt.jp-OutputArea-prompt:'\n",
    "             + 'empty {padding: 0; border: 0;}</style>'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm as tqdm\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../mouseland/model_opts')\n",
    "from feature_extraction import *\n",
    "from model_options import *\n",
    "from image_ops import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'vessel_assets/'\n",
    "assets = glob(root + '*.jpg')\n",
    "dictlist = []\n",
    "for asset in assets:\n",
    "    imgstr = asset.split('/')[1]\n",
    "    row = {'ImageName': imgstr}\n",
    "    dictlist.append(row)\n",
    "image_df = pd.DataFrame(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StimulusSet(Dataset):\n",
    "    def __init__(self, csv, root_dir, image_transforms=None):\n",
    "        \n",
    "        self.root = os.path.expanduser(root_dir)\n",
    "        self.transforms = image_transforms\n",
    "        \n",
    "        if isinstance(csv, pd.DataFrame):\n",
    "            self.df = csv\n",
    "        if isinstance(csv, str):\n",
    "            self.df = pd.read_csv(csv)\n",
    "        \n",
    "        self.images = self.df.ImageName\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = os.path.join(self.root, self.images.iloc[index])\n",
    "        img = Image.open(filename).convert('RGB')\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "            \n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Array2DataLoader(Dataset):\n",
    "    def __init__(self, img_array, image_transforms=None):\n",
    "        self.transforms = image_transforms\n",
    "        if isinstance(img_array, np.ndarray):\n",
    "            self.images = img_array\n",
    "        if isinstance(img_array, str):\n",
    "            self.images = np.load(img_array)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.fromarray(self.images[index]).convert('RGB')\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_string = 'alexnet_imagenet'\n",
    "\n",
    "model_options = get_model_options()\n",
    "image_transforms = get_recommended_transforms(model_string)\n",
    "model_name = model_options[model_string]['model_name']\n",
    "train_type = model_options[model_string]['train_type']\n",
    "model_call = model_options[model_string]['call']\n",
    "\n",
    "model = eval(model_call)\n",
    "model = model.eval()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_loader = DataLoader(dataset=StimulusSet(image_df, root, image_transforms), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_features = get_all_feature_maps(model, stimulus_loader, numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_images = np.load('../datasets/samples/imagenet_eval_sample.npy')\n",
    "train_images = np.load('../datasets/samples/imagenet_train_sample.npy')\n",
    "imagenet_images = np.concatenate((train_images, eval_images), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_loader = DataLoader(dataset=Array2DataLoader(imagenet_images, image_transforms), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_features = get_all_feature_maps(model, imagenet_loader, numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_features['Conv2d-1'].shape, stimulus_features['Conv2d-1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_feature_map = stimulus_features['Conv2d-1'][0]\n",
    "sample_feature_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treves_rolls(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return ((np.sum(x / x.shape[0]))**2 / np.sum(x**2 / x.shape[0]))\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return ((torch.sum(x / x.shape[0]))**2 / torch.sum(x**2 / x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_dictlist = []\n",
    "for map_key_i, map_key in enumerate(tqdm(stimulus_features)):\n",
    "    target_map = stimulus_features[map_key]\n",
    "    for target_i, target_activity in enumerate(target_map):\n",
    "        image_name = image_df.ImageName.iloc[target_i]\n",
    "        \n",
    "        activity_dictlist.append({\n",
    "            'image': image_name, \n",
    "            'model': model_name,\n",
    "            'train_type': train_type,\n",
    "            'model_layer': map_key, \n",
    "            'model_layer_index': map_key.split('-')[1],\n",
    "            'model_layer_depth': map_key_i,\n",
    "            'max_activity': target_activity.abs().max().item(),\n",
    "            'mean_activity': target_activity.abs().mean().item(),\n",
    "            'sparseness': treves_rolls(target_activity).item()\n",
    "        })\n",
    "        \n",
    "activity_df = pd.DataFrame(activity_dictlist)\n",
    "stim_info = pd.DataFrame(activity_dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(activity_df.mean_activity, activity_df.sparseness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_dictlist = []\n",
    "for map_key_i, map_key in enumerate(tqdm(imagenet_features)):\n",
    "    target_map = imagenet_features[map_key]\n",
    "    for target_i, target_activity in enumerate(target_map):\n",
    "        if target_i < 1000:\n",
    "            image_source = 'imagenet_train'\n",
    "        if target_i > 1000:\n",
    "            image_source = 'imagenet_val'\n",
    "        \n",
    "        activity_dictlist.append({\n",
    "            'image': target_i, \n",
    "            'model': model_name,\n",
    "            'train_type': train_type,\n",
    "            'model_layer': map_key, \n",
    "            'model_layer_index': map_key.split('-')[1],\n",
    "            'model_layer_depth': map_key_i,\n",
    "            'max_activity': target_activity.abs().max().item(),\n",
    "            'mean_activity': target_activity.abs().mean().item(),\n",
    "            'sparseness': treves_rolls(target_activity).item(),\n",
    "            'image_source': image_source,\n",
    "        })\n",
    "        \n",
    "activity_df = pd.DataFrame(activity_dictlist)\n",
    "imgnet_info = pd.DataFrame(activity_dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_df = deepcopy(stim_info)\n",
    "stim_df['image_source'] = 'vessel'\n",
    "imgnet_df = deepcopy(imgnet_info)\n",
    "imgnet_df['image'] = 'imagenet_' + imgnet_df['image'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df = pd.concat([stim_df,imgnet_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_df.to_csv('results/alexnet_special.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='model_layer_depth', y='sparseness', data = imgnet_info);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='model_layer_depth', y='mean_activity', data = imgnet_info);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgnet_info.groupby('model_layer_depth')['sparseness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
