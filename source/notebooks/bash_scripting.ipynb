{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, stat\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../model_opts')\n",
    "from model_options import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_incomplete_models(model_options, results_dir):\n",
    "    if os.path.exists(results_dir):\n",
    "        complete_models = [model_string.split('.')[0] for model_string in os.listdir(results_dir)]\n",
    "        incomplete_models = [model_string for model_string in model_options\n",
    "                            if model_string not in complete_models]\n",
    "\n",
    "        return(incomplete_models)\n",
    "    \n",
    "    if not os.path.exists(results_dir):\n",
    "        return model_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm import list_models\n",
    "list_models(pretrained=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group-Affect Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_strings = {#**get_model_options(train_type = 'imagenet', model_source = 'torchvision'),\n",
    "                 #**get_model_options(train_type = 'imagenet', model_source = 'timm'),\n",
    "                 **get_model_options(model_source = 'detectron'),\n",
    "                 **get_model_options(train_type = 'taskonomy'),\n",
    "                 **get_model_options(train_data = 'Instagram'),\n",
    "                 **get_model_options(train_data = 'big_transfer'),\n",
    "                 **get_model_options(train_data = 'imagenet21k'),\n",
    "                 #**get_model_options(train_type = 'semi-supervised'),\n",
    "                 #**get_model_options(model_source = 'midas'),\n",
    "                 #**get_model_options(train_type = 'custom'),\n",
    "                 **get_model_options(model_source = 'dino'),\n",
    "                 **get_model_options(model_source = 'clip'),\n",
    "                 **get_model_options(model_source = 'vissl')}\n",
    "\n",
    "output_shfile = 'feature_analysis.sh'\n",
    "\n",
    "commands = []\n",
    "imagesets = ['oasis','vessel']\n",
    "for model_string in model_strings:\n",
    "    for imageset in imagesets:\n",
    "        if model_string in subset_incomplete_models(model_strings, 'incoming/reg_redux/{}'.format(imageset)):\n",
    "            command = \"python feature_analysis2.py\"\n",
    "            command += \" --model_string \" + model_string\n",
    "            command += ' --imageset ' + imageset\n",
    "            commands.append(command)\n",
    "\n",
    "with open(output_shfile, 'w') as file:\n",
    "    file.write(\"\\n\".join(commands))\n",
    "    \n",
    "os.chmod(output_shfile, os.stat(output_shfile).st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_strings = {**get_model_options(train_type = 'imagenet', model_source = 'torchvision'),\n",
    "                 **get_model_options(train_type = 'imagenet', model_source = 'timm'),\n",
    "                 #**get_model_options(model_source = 'detectron'),\n",
    "                 #**get_model_options(train_type = 'taskonomy'),\n",
    "                 **get_model_options(train_data = 'Instagram'),\n",
    "                 **get_model_options(train_data = 'big_transfer'),\n",
    "                 **get_model_options(train_data = 'imagenet21k'),\n",
    "                 #**get_model_options(model_source = 'midas'),\n",
    "                 **get_model_options(model_source = 'dino'),\n",
    "                 **get_model_options(model_source = 'clip'),\n",
    "                 **get_model_options(model_source = 'vissl')}\n",
    "\n",
    "models_to_run = pd.read_csv('../superlative_layers.csv').model_string\n",
    "\n",
    "output_shfile = 'subject_regressions.sh'\n",
    "\n",
    "commands = []\n",
    "imagesets = ['oasis','vessel']\n",
    "for imageset in imagesets:\n",
    "    for model_string in model_strings:\n",
    "        if model_string in models_to_run.to_list():\n",
    "            if model_string in subset_incomplete_models(model_strings, 'incoming/subject_regs/{}'.format(imageset)):\n",
    "                command = \"python subject_regressions.py\"\n",
    "                command += \" --model_string \" + model_string\n",
    "                command += ' --imageset ' + imageset\n",
    "                commands.append(command)\n",
    "\n",
    "with open(output_shfile, 'w') as file:\n",
    "    file.write(\"\\n\".join(commands))\n",
    "    \n",
    "os.chmod(output_shfile, os.stat(output_shfile).st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_strings = {**get_model_options(train_type = 'imagenet', model_source = 'torchvision'),\n",
    "                 **get_model_options(train_type = 'imagenet', model_source = 'timm'),\n",
    "                 #**get_model_options(model_source = 'detectron'),\n",
    "                 #**get_model_options(train_type = 'taskonomy'),\n",
    "                 #**get_model_options(model_source = 'midas'),\n",
    "                 **get_model_options(model_source = 'dino'),\n",
    "                 **get_model_options(model_source = 'clip'),\n",
    "                 **get_model_options(model_source = 'vissl')}\n",
    "\n",
    "models_to_run = pd.read_csv('../results/superlative_layers.csv').model_string\n",
    "\n",
    "output_shfile = 'cross_decoding.sh'\n",
    "\n",
    "commands = []\n",
    "cross_types = ['image_type','affect']\n",
    "for cross_type in cross_types:\n",
    "    for model_string in model_strings:\n",
    "        if model_string in models_to_run.to_list():\n",
    "            if model_string in subset_incomplete_models(model_strings, 'incoming/cross_regs/{}'.format(cross_type)):\n",
    "                command = \"python cross_decoding.py\"\n",
    "                command += \" --model_string \" + model_string\n",
    "                command += ' --cross_type ' + cross_type\n",
    "                commands.append(command)\n",
    "\n",
    "with open(output_shfile, 'w') as file:\n",
    "    file.write(\"\\n\".join(commands))\n",
    "    \n",
    "os.chmod(output_shfile, os.stat(output_shfile).st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_strings = {**get_model_options(train_type = 'imagenet', model_source = 'torchvision'),\n",
    "                 **get_model_options(train_type = 'imagenet', model_source = 'timm'),\n",
    "                 **get_model_options(model_source = 'detectron'),\n",
    "                 **get_model_options(train_type = 'taskonomy'),\n",
    "                 **get_model_options(train_data = 'Instagram'),\n",
    "                 **get_model_options(train_data = 'big_transfer'),\n",
    "                 **get_model_options(train_data = 'imagenet21k'),\n",
    "                 **get_model_options(train_type = 'taskonomy'),\n",
    "                 #**get_model_options(model_source = 'midas'),\n",
    "                 **get_model_options(model_source = 'dino'),\n",
    "                 **get_model_options(model_source = 'clip'),\n",
    "                 **get_model_options(model_source = 'vissl')}\n",
    "\n",
    "models_to_run = pd.read_csv('../results/superlative_layers.csv').model_string\n",
    "\n",
    "output_shfile = 'bootstrapping.sh'\n",
    "\n",
    "commands = []\n",
    "imagesets = ['oasis','vessel']\n",
    "for imageset in imagesets:\n",
    "    for model_string in model_strings:\n",
    "        if model_string in models_to_run.to_list():\n",
    "            results_folder = 'incoming/bootstrapping/{}'.format(imageset)\n",
    "            if model_string in subset_incomplete_models(model_strings, results_folder):\n",
    "                command = \"python bootstrapping.py\"\n",
    "                command += \" --model_string \" + model_string\n",
    "                command += ' --imageset ' + imageset\n",
    "                commands.append(command)\n",
    "\n",
    "with open(output_shfile, 'w') as file:\n",
    "    file.write(\"\\n\".join(commands))\n",
    "    \n",
    "os.chmod(output_shfile, os.stat(output_shfile).st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLIP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['ViT-S-SimCLR','ViT-S-CLIP','ViT-S-SLIP', 'ViT-S-SLIP-Ep100',\n",
    "                'ViT-B-SimCLR','ViT-B-CLIP','ViT-B-SLIP','ViT-B-SLIP-Ep100',\n",
    "                'ViT-L-SimCLR','ViT-L-CLIP','ViT-L-SLIP','ViT-L-SLIP-Ep100',\n",
    "                'ViT-L-CLIP-CC12M','ViT-L-SLIP-CC12M']\n",
    "\n",
    "output_shfile = 'slip_models.sh'\n",
    "\n",
    "commands = []\n",
    "imagesets = ['oasis','vessel']\n",
    "for imageset in imagesets:\n",
    "    for model_name in model_names:\n",
    "        command = \"python slip_models.py\"\n",
    "        command += \" --model_name \" + model_name\n",
    "        command += ' --imageset ' + imageset\n",
    "        command += ' --output_type ' + 'parquet'\n",
    "        commands.append(command)\n",
    "\n",
    "with open(output_shfile, 'w') as file:\n",
    "    file.write(\"\\n\".join(commands))\n",
    "    \n",
    "os.chmod(output_shfile, os.stat(output_shfile).st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEER Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['RegNet-32Gf-SEER', 'RegNet-32Gf-SEER-INFT', 'RegNet-64Gf-SEER', 'RegNet-64Gf-SEER-INFT', \n",
    "               'RegNet-128Gf-SEER', 'RegNet-128Gf-SEER-INFT', 'RegNet-256Gf-SEER', 'RegNet-256Gf-SEER-INFT']\n",
    "\n",
    "output_shfile = 'seer_models.sh'\n",
    "\n",
    "commands = []\n",
    "imagesets = ['oasis','vessel']\n",
    "for imageset in imagesets:\n",
    "    for model_name in model_names:\n",
    "        command = \"python seer_models.py\"\n",
    "        command += \" --model_name \" + model_name\n",
    "        command += ' --imageset ' + imageset\n",
    "        command += ' --output_type ' + 'parquet'\n",
    "        commands.append(command)\n",
    "\n",
    "with open(output_shfile, 'w') as file:\n",
    "    file.write(\"\\n\".join(commands))\n",
    "    \n",
    "os.chmod(output_shfile, os.stat(output_shfile).st_mode | stat.S_IEXEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "primary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
